import pandas as pd
from sqlalchemy import create_engine, inspect, text, event
import os

def import_from_pkl(db_config, file_path, import_scope="all", source_name=None, target_table=None, if_exists="replace", collation="server_default", stop_on_mismatch=True, excluded_columns=None, logger=None):
    """
    Imports a Pickle file to MySQL. Supports both single table and full import.

    Args:
        db_config (dict): Dictionary with keys 'host', 'port', 'user', 'password', 'database'.
        file_path (str): Path to the Pickle file.
        import_scope (str): 'single' for specific table, 'all' for full import.
        source_name (str, optional): Dictionary key to extract (for single mode with dict pickle).
        target_table (str, optional): Target table name (for single mode).
        if_exists (str): 'replace' to drop existing table, 'append' to add to existing table.
        collation (str): Target collation, or 'server_default'.
        stop_on_mismatch (bool): Stop import when collation mismatch is detected.
        excluded_columns (dict, optional): {table_name: [col_names_to_exclude]}.
        logger (callable, optional): Logging function. Defaults to print.
    """
    log = logger or print
    try:
        db_url = (
            f"mysql+pymysql://{db_config['user']}:{db_config['password']}"
            f"@{db_config['host']}:{int(db_config['port'])}/{db_config['database']}?charset=utf8mb4"
        )
        engine = create_engine(db_url)
        desired_collation = _normalize_collation(collation)
        _configure_engine_collation(engine, desired_collation)
        schema_collation = _get_schema_collation(engine, db_config['database'])
        selected_text = desired_collation or "server_default"
        if schema_collation:
            log(f"â„¹ï¸ [pkl2mysql] ì„ íƒ ì½œë ˆì´ì…˜: {selected_text} (DB ê¸°ë³¸: {schema_collation})")
        else:
            log(f"â„¹ï¸ [pkl2mysql] ì„ íƒ ì½œë ˆì´ì…˜: {selected_text}")
        log(f"âœ… [pkl2mysql] ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ!")

        # Load pickle file
        data = pd.read_pickle(file_path)

        # Determine tables to import based on scope
        if import_scope == "single":
            # Single table import
            if isinstance(data, dict):
                # Dictionary: Extract specific key
                if source_name:
                    if source_name not in data:
                        raise ValueError(f"í‚¤ '{source_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤: {', '.join(data.keys())}")
                    df = data[source_name]
                    log(f"âœ… [pkl2mysql] Dictionaryì—ì„œ í‚¤ '{source_name}' ì¶”ì¶œ ì™„ë£Œ: {df.shape[0]} rows, {df.shape[1]} columns")
                else:
                    raise ValueError("Dictionary Pickleì—ì„œ íŠ¹ì • í…Œì´ë¸”ì„ Importí•˜ë ¤ë©´ ì†ŒìŠ¤ ì§€ì •(í‚¤)ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            else:
                # DataFrame: Use as-is
                df = data
                log(f"âœ… [pkl2mysql] DataFrame ë¡œë”© ì™„ë£Œ: {df.shape[0]} rows, {df.shape[1]} columns")

            if not target_table:
                raise ValueError("íŠ¹ì • í…Œì´ë¸” Import ëª¨ë“œì—ì„œëŠ” ëŒ€ìƒ í…Œì´ë¸”ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.")

            tables_to_import = {target_table: df}

        else:
            # Full import
            if isinstance(data, dict):
                # Dictionary: Use all key-value pairs
                log(f"âœ… [pkl2mysql] Dictionary í˜•ì‹ Pickle ë¡œë”© ì™„ë£Œ: {len(data)}ê°œ í…Œì´ë¸”")
                tables_to_import = data
            else:
                # DataFrame: Use filename as table name
                df = data
                log(f"âœ… [pkl2mysql] DataFrame ë¡œë”© ì™„ë£Œ: {df.shape[0]} rows, {df.shape[1]} columns")
                table_name = os.path.basename(file_path).split('.')[0]
                log(f"â„¹ï¸ [pkl2mysql] íŒŒì¼ëª…ì„ í…Œì´ë¸”ëª…ìœ¼ë¡œ ì‚¬ìš©: '{table_name}'")
                tables_to_import = {table_name: df}

        # Process each table
        imported_count = 0
        inspector = inspect(engine)
        existing_tables = set(inspector.get_table_names())

        for tbl_name, df in tables_to_import.items():
            log(f"\nâ–¶ [pkl2mysql] í…Œì´ë¸” '{tbl_name}' ì²˜ë¦¬ ì¤‘... ({df.shape[0]} rows, {df.shape[1]} columns)")

            # Clean column names
            df.columns = [col.strip().replace(" ", "_").lower() for col in df.columns]

            # Drop excluded columns
            cols_to_drop = []
            if excluded_columns and tbl_name in excluded_columns:
                cols_to_drop = [c for c in excluded_columns[tbl_name] if c in df.columns]
                if cols_to_drop:
                    df = df.drop(columns=cols_to_drop)
                    log(f"  â­ï¸ ì œì™¸ëœ ì»¬ëŸ¼: {', '.join(cols_to_drop)}")

            table_existed = tbl_name in existing_tables
            if table_existed:
                _report_existing_table_collation(engine, db_config['database'], tbl_name, log)
                if desired_collation:
                    mismatch = _report_collation_mismatch(engine, db_config['database'], tbl_name, desired_collation, schema_collation, log)
                    if mismatch and stop_on_mismatch:
                        raise ValueError(f"ì½œë ˆì´ì…˜ ë¶ˆì¼ì¹˜ë¡œ ì¤‘ë‹¨: í…Œì´ë¸” '{tbl_name}'")
            elif import_scope == "single":
                log(f"  â„¹ï¸ ëŒ€ìƒ í…Œì´ë¸” '{tbl_name}' ë¯¸ì¡´ì¬: ì‹ ê·œ ìƒì„± ì˜ˆì •")

            # Replace + existing table + excluded columns â†’ TRUNCATE + append to preserve schema
            effective_if_exists = if_exists
            if if_exists == "replace" and table_existed and cols_to_drop:
                _truncate_table(engine, tbl_name, log)
                effective_if_exists = "append"

            # Import based on if_exists mode using pandas.to_sql
            _import_single_table(df, tbl_name, engine, effective_if_exists, desired_collation, table_existed, log)

            imported_count += 1

        scope_text = f"'{target_table}'" if import_scope == "single" else f"{imported_count}ê°œ í…Œì´ë¸”"
        log(f"\nğŸ‰ [pkl2mysql] {scope_text} Import ì™„ë£Œ!")
        return True

    except Exception as e:
        log(f"âŒ [pkl2mysql] ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise e
    finally:
        pass


def _insert_ignore(table, conn, keys, data_iter):
    """Custom insert method for pandas to_sql that uses INSERT IGNORE."""
    from sqlalchemy.dialects.mysql import insert
    data = [dict(zip(keys, row)) for row in data_iter]
    stmt = insert(table.table).prefix_with("IGNORE").values(data)
    conn.execute(stmt)


def _import_single_table(df, table_name, engine, if_exists, desired_collation, table_existed, log=print):
    """Import a single DataFrame to MySQL table using pandas.to_sql."""
    # Clean column names
    df.columns = [col.strip().replace(" ", "_").lower() for col in df.columns]

    # _x000D_ ì²˜ë¦¬ (Excel íŠ¹ìˆ˜ ë¬¸ìì™€ ë™ì¼í•˜ê²Œ ì •ë¦¬)
    for col in df.select_dtypes(include=['object']).columns:
        df[col] = df[col].str.replace('_x000D_', '', regex=False)

    mode_text = "ëŒ€ì²´" if if_exists == "replace" else "ì¶”ê°€"

    if if_exists == "replace":
        if table_existed:
            log(f"  ğŸ—‘ï¸ ê¸°ì¡´ í…Œì´ë¸” '{table_name}' ì‚­ì œ í›„ ì¬ìƒì„±")
        else:
            log(f"  â„¹ï¸ í…Œì´ë¸” '{table_name}' ì‹ ê·œ ìƒì„±")
    else:
        if table_existed:
            log(f"  âœ… ê¸°ì¡´ í…Œì´ë¸” '{table_name}'ì— ë°ì´í„° ì¶”ê°€ (ì¤‘ë³µ í‚¤ Skip)")
        else:
            log(f"  â„¹ï¸ í…Œì´ë¸” '{table_name}' ì‹ ê·œ ìƒì„± í›„ ë°ì´í„° ì‚½ì…")

    log(f"  â–¶ Import ì¤‘ ({mode_text} ëª¨ë“œ)...")
    method = _insert_ignore if (if_exists == "append" and table_existed) else "multi"
    df.to_sql(name=table_name, con=engine, index=False, if_exists=if_exists, method=method)
    _apply_table_collation(engine, table_name, desired_collation, table_existed, if_exists, log)
    log(f"  âœ… {len(df)} rows Import ì™„ë£Œ")


def _normalize_collation(collation):
    if not collation or collation == "server_default":
        return None
    return collation


def _configure_engine_collation(engine, desired_collation):
    if not desired_collation:
        return

    if getattr(engine, "_sqlhandler_collation", None) == desired_collation:
        return

    engine._sqlhandler_collation = desired_collation

    @event.listens_for(engine, "connect")
    def _set_collation(dbapi_connection, _):
        cursor = dbapi_connection.cursor()
        cursor.execute(f"SET NAMES utf8mb4 COLLATE {desired_collation}")
        cursor.execute(f"SET SESSION collation_connection='{desired_collation}'")
        cursor.close()


def _truncate_table(engine, table_name, log=print):
    """TRUNCATE table to clear data while preserving schema."""
    safe_table = _escape_identifier(table_name)
    with engine.begin() as conn:
        conn.execute(text(f"TRUNCATE TABLE `{safe_table}`"))
    log(f"  ğŸ—‘ï¸ ê¸°ì¡´ í…Œì´ë¸” '{table_name}' ë°ì´í„° ì´ˆê¸°í™” (ìŠ¤í‚¤ë§ˆ ë³´ì¡´)")


def _escape_identifier(name):
    return name.replace("`", "``")


def _report_existing_table_collation(engine, db_name, table_name, log=print):
    with engine.connect() as conn:
        table_sql = text(
            """
            SELECT TABLE_COLLATION
            FROM information_schema.tables
            WHERE table_schema = :db AND table_name = :tbl
            """
        )
        result = conn.execute(table_sql, {"db": db_name, "tbl": table_name}).scalar()
        if result:
            log(f"  â„¹ï¸ ê¸°ì¡´ í…Œì´ë¸” ì½œë ˆì´ì…˜: '{table_name}' = {result}")


def _report_collation_mismatch(engine, db_name, table_name, desired_collation, schema_collation, log=print):
    has_mismatch = False
    with engine.connect() as conn:
        table_sql = text(
            """
            SELECT TABLE_COLLATION
            FROM information_schema.tables
            WHERE table_schema = :db AND table_name = :tbl
            """
        )
        result = conn.execute(table_sql, {"db": db_name, "tbl": table_name}).scalar()
        if result:
            if result == desired_collation:
                log(f"  âœ… í…Œì´ë¸” ì½œë ˆì´ì…˜ ì¼ì¹˜: '{table_name}' = {result}")
            else:
                db_default_text = f"DB ê¸°ë³¸: {schema_collation}" if schema_collation else "DB ê¸°ë³¸: ì•Œ ìˆ˜ ì—†ìŒ"
                log(f"  âš ï¸ í…Œì´ë¸” ì½œë ˆì´ì…˜ ë¶ˆì¼ì¹˜: '{table_name}' = {result} (ì„ íƒ: {desired_collation}, {db_default_text})")
                has_mismatch = True

        col_sql = text(
            """
            SELECT column_name, collation_name
            FROM information_schema.columns
            WHERE table_schema = :db AND table_name = :tbl AND collation_name IS NOT NULL
            """
        )
        rows = conn.execute(col_sql, {"db": db_name, "tbl": table_name}).fetchall()
        mismatched = [(r[0], r[1]) for r in rows if r[1] and r[1] != desired_collation]
        if mismatched:
            log("  âš ï¸ ì»¬ëŸ¼ ì½œë ˆì´ì…˜ ë¶ˆì¼ì¹˜ ëª©ë¡:")
            for col_name, collation_name in mismatched:
                log(f"    - {col_name}: {collation_name}")
            has_mismatch = True
    return has_mismatch


def _apply_table_collation(engine, table_name, desired_collation, table_existed, if_exists, log=print):
    if not desired_collation:
        return

    if if_exists == "append" and table_existed:
        log("  â„¹ï¸ Append ëª¨ë“œ + ê¸°ì¡´ í…Œì´ë¸”: ì½œë ˆì´ì…˜ ë³€ê²½í•˜ì§€ ì•Šê³  ì§„í–‰")
        return

    safe_table = _escape_identifier(table_name)
    alter_sql = f"ALTER TABLE `{safe_table}` CONVERT TO CHARACTER SET utf8mb4 COLLATE {desired_collation}"
    with engine.begin() as conn:
        conn.execute(text(alter_sql))
    log(f"  âœ… ì½œë ˆì´ì…˜ ì ìš© ì™„ë£Œ: {desired_collation}")


def _get_schema_collation(engine, db_name):
    with engine.connect() as conn:
        sql = text(
            """
            SELECT DEFAULT_COLLATION_NAME
            FROM information_schema.schemata
            WHERE schema_name = :db
            """
        )
        return conn.execute(sql, {"db": db_name}).scalar()
